{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7049972,"sourceType":"datasetVersion","datasetId":4057182}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install -U scikit-learn\n! pip install -U pyarrow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-14T22:23:44.866729Z","iopub.execute_input":"2023-12-14T22:23:44.867100Z","iopub.status.idle":"2023-12-14T22:24:08.774250Z","shell.execute_reply.started":"2023-12-14T22:23:44.867069Z","shell.execute_reply":"2023-12-14T22:24:08.772921Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.3.2)\nRequirement already satisfied: numpy<2.0,>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.24.3)\nRequirement already satisfied: scipy>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (14.0.1)\nRequirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.10/site-packages (from pyarrow) (1.24.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd     # For loading and processing the dataset\nimport gc\nimport tensorflow as tf   \nfrom tensorflow import keras\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OrdinalEncoder,MinMaxScaler\nfrom sklearn.metrics import mutual_info_score\nfrom sklearn.decomposition import PCA","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:24:08.777049Z","iopub.execute_input":"2023-12-14T22:24:08.777978Z","iopub.status.idle":"2023-12-14T22:24:08.785562Z","shell.execute_reply.started":"2023-12-14T22:24:08.777929Z","shell.execute_reply":"2023-12-14T22:24:08.784520Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"gc.collect() # For performing a full garbage collection","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:24:08.786726Z","iopub.execute_input":"2023-12-14T22:24:08.787037Z","iopub.status.idle":"2023-12-14T22:24:09.092722Z","shell.execute_reply.started":"2023-12-14T22:24:08.787009Z","shell.execute_reply":"2023-12-14T22:24:09.091665Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"289"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Reading and cleaning the input data**\nI read the CSV input file using Pandas. Next, I remove irrelevant entries, and prepare the data for our neural network.","metadata":{}},{"cell_type":"code","source":"# Read the CSV input file and show first 5 rows\ndata=pd.read_csv('/kaggle/input/affinity-data/binding_affinity_data.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:24:09.094955Z","iopub.execute_input":"2023-12-14T22:24:09.095307Z","iopub.status.idle":"2023-12-14T22:24:14.905341Z","shell.execute_reply.started":"2023-12-14T22:24:09.095248Z","shell.execute_reply":"2023-12-14T22:24:14.904266Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                       MHC_sequence     MHC_type  \\\n0           0  MRVTAPRTLLLLLWGAVALTETWAGSHSMRYFHTSVSRPGRGEPRF...  HLA-B*27:05   \n1           1  MRVTAPRTLLLLLWGAVALTETWAGSHSMRYFHTSVSRPGRGEPRF...  HLA-B*27:05   \n2           2  MRVTAPRTLLLLLWGAVALTETWAGSHSMRYFHTSVSRPGRGEPRF...  HLA-B*27:05   \n3           3  MRVTAPRTLLLLLWGAVALTETWAGSHSMRYFHTSVSRPGRGEPRF...  HLA-B*27:05   \n4           4  MRVTAPRTLLLLLWGAVALTETWAGSHSMRYFHTSVSRPGRGEPRF...  HLA-B*27:05   \n\n  peptide_sequence  label  \n0        ERLKEVQKR      1  \n1    KPRKTAEVAGKTL      1  \n2        KEARRIIKK      1  \n3       EEKITEAKEL      0  \n4     SLPSSRAARVPG      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>MHC_sequence</th>\n      <th>MHC_type</th>\n      <th>peptide_sequence</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>MRVTAPRTLLLLLWGAVALTETWAGSHSMRYFHTSVSRPGRGEPRF...</td>\n      <td>HLA-B*27:05</td>\n      <td>ERLKEVQKR</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>MRVTAPRTLLLLLWGAVALTETWAGSHSMRYFHTSVSRPGRGEPRF...</td>\n      <td>HLA-B*27:05</td>\n      <td>KPRKTAEVAGKTL</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>MRVTAPRTLLLLLWGAVALTETWAGSHSMRYFHTSVSRPGRGEPRF...</td>\n      <td>HLA-B*27:05</td>\n      <td>KEARRIIKK</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>MRVTAPRTLLLLLWGAVALTETWAGSHSMRYFHTSVSRPGRGEPRF...</td>\n      <td>HLA-B*27:05</td>\n      <td>EEKITEAKEL</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>MRVTAPRTLLLLLWGAVALTETWAGSHSMRYFHTSVSRPGRGEPRF...</td>\n      <td>HLA-B*27:05</td>\n      <td>SLPSSRAARVPG</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:24:14.906592Z","iopub.execute_input":"2023-12-14T22:24:14.906963Z","iopub.status.idle":"2023-12-14T22:24:14.918500Z","shell.execute_reply.started":"2023-12-14T22:24:14.906927Z","shell.execute_reply":"2023-12-14T22:24:14.917533Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1793065 entries, 0 to 1793064\nData columns (total 5 columns):\n #   Column            Dtype \n---  ------            ----- \n 0   Unnamed: 0        int64 \n 1   MHC_sequence      object\n 2   MHC_type          object\n 3   peptide_sequence  object\n 4   label             int64 \ndtypes: int64(2), object(3)\nmemory usage: 68.4+ MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Remove unused features**\nI should delete unused features from my dataset to increase performance and decrease complexity. some features like *id* or *Unnamed : 0* (in our dataset) is obviously unused so I can easily delete them but for another feature I should use some techniques which name is **feature selection**.\nby using feature selection techniques, I can identify and delete the most irrelevant features from the model's features.","metadata":{}},{"cell_type":"code","source":"# We can't do anything with the 'Unnamed: 0', so we drop it.\ndata = data.drop(['Unnamed: 0'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:24:14.919838Z","iopub.execute_input":"2023-12-14T22:24:14.920516Z","iopub.status.idle":"2023-12-14T22:24:14.976955Z","shell.execute_reply.started":"2023-12-14T22:24:14.920481Z","shell.execute_reply":"2023-12-14T22:24:14.975945Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"before using feature selection, I should do some preprocessing stages for preparing data for that operation.","metadata":{}},{"cell_type":"markdown","source":"# **Handling missing values**\n\nMy dataset may contains missing values, I should choose to either remove the samples with missing values or impute the missing values using techniques like mean imputation or regression or KNN imputation.","metadata":{}},{"cell_type":"code","source":"data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:24:14.978240Z","iopub.execute_input":"2023-12-14T22:24:14.978613Z","iopub.status.idle":"2023-12-14T22:24:15.446912Z","shell.execute_reply.started":"2023-12-14T22:24:14.978578Z","shell.execute_reply":"2023-12-14T22:24:15.445897Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"MHC_sequence        0\nMHC_type            0\npeptide_sequence    0\nlabel               0\ndtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"As you can see I dont have missing values in my dataset.","metadata":{}},{"cell_type":"markdown","source":"# **Encoding Stage**\nThe encoding stage in preprocessing data for neural networks involves transforming the raw input data into a format that can be effectively processed by the neural network model.","metadata":{}},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:24:15.448424Z","iopub.execute_input":"2023-12-14T22:24:15.449267Z","iopub.status.idle":"2023-12-14T22:24:15.459670Z","shell.execute_reply.started":"2023-12-14T22:24:15.449197Z","shell.execute_reply":"2023-12-14T22:24:15.458740Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1793065 entries, 0 to 1793064\nData columns (total 4 columns):\n #   Column            Dtype \n---  ------            ----- \n 0   MHC_sequence      object\n 1   MHC_type          object\n 2   peptide_sequence  object\n 3   label             int64 \ndtypes: int64(1), object(3)\nmemory usage: 54.7+ MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"I need to convert three object-type features into numerical representations. Initially, I use ordinal encoding to transform the MHC_type features into a valid structure. This approach is chosen due to the large amount of data and limited resources available. Additionally, it has been proven that ordinal encoding does not affect the performance of the neural network prediction in this case.\n","metadata":{}},{"cell_type":"code","source":"encoder = OrdinalEncoder()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:24:15.460852Z","iopub.execute_input":"2023-12-14T22:24:15.461156Z","iopub.status.idle":"2023-12-14T22:24:15.470105Z","shell.execute_reply.started":"2023-12-14T22:24:15.461132Z","shell.execute_reply":"2023-12-14T22:24:15.469033Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"data['MHC_type'] = encoder.fit_transform(data[['MHC_type']])","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:24:15.474872Z","iopub.execute_input":"2023-12-14T22:24:15.475287Z","iopub.status.idle":"2023-12-14T22:24:15.983656Z","shell.execute_reply.started":"2023-12-14T22:24:15.475213Z","shell.execute_reply":"2023-12-14T22:24:15.982858Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"for two other features (\"MHC_sequence\" and \"peptide_sequence\") I use character-level encoding approach. I want to encode strings into numeric values while considering their similarity and allowing close strings to have close numeric values because of that I use that approach.","metadata":{}},{"cell_type":"code","source":"def encode_string(string,length):\n    encoding = []\n    for char in string:\n        encoding.append(ord(char))  # Get the ASCII code for each character\n    \n    for i in range(length-len(string)):\n        encoding.append(0)\n        \n    return encoding\n\nmax_len_mhc=sorted([len(i) for i in data['MHC_sequence']])[-1]\nmax_len_peptide=sorted([len(i) for i in data['peptide_sequence']])[-1]\n\nmhc_sequence=[]\npeptide_sequence=[]\n\nfor i in data['MHC_sequence'].values:\n    mhc_sequence.append(encode_string(i,max_len_mhc))\n    \nfor i in data['peptide_sequence'].values:\n    peptide_sequence.append(encode_string(i,max_len_peptide))","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:24:15.984878Z","iopub.execute_input":"2023-12-14T22:24:15.985264Z","iopub.status.idle":"2023-12-14T22:26:11.109957Z","shell.execute_reply.started":"2023-12-14T22:24:15.985207Z","shell.execute_reply":"2023-12-14T22:26:11.109147Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"I utilize the Principal Component Analysis (PCA) algorithm as a means to effectively reduce the dimensionality of the dataset by applying it to these two specific features. This allows me to extract the most significant information from the features while minimizing the loss of valuable data.","metadata":{}},{"cell_type":"code","source":"mhc_sequence=np.array(mhc_sequence).astype(np.float64)\npeptide_sequence=np.array(peptide_sequence).astype(np.float64)\n\npca = PCA(n_components=1)  # Specify the number of components you want to keep\ndata['MHC_sequence'] = pca.fit_transform(mhc_sequence)\ndata['peptide_sequence']=pca.fit_transform(peptide_sequence)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:26:11.111420Z","iopub.execute_input":"2023-12-14T22:26:11.111728Z","iopub.status.idle":"2023-12-14T22:27:50.990868Z","shell.execute_reply.started":"2023-12-14T22:26:11.111702Z","shell.execute_reply":"2023-12-14T22:27:50.989926Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:27:50.992185Z","iopub.execute_input":"2023-12-14T22:27:50.992515Z","iopub.status.idle":"2023-12-14T22:27:51.003817Z","shell.execute_reply.started":"2023-12-14T22:27:50.992488Z","shell.execute_reply":"2023-12-14T22:27:51.002867Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1793065 entries, 0 to 1793064\nData columns (total 4 columns):\n #   Column            Dtype  \n---  ------            -----  \n 0   MHC_sequence      float64\n 1   MHC_type          float64\n 2   peptide_sequence  float64\n 3   label             int64  \ndtypes: float64(3), int64(1)\nmemory usage: 54.7 MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"At this stage, we can see that the two features MHC_sequence and MHC_type are very similar and relevent.  In order to optimize memory consumption, we merge the two columns using the PCA algorithm.","metadata":{}},{"cell_type":"code","source":"scaler = MinMaxScaler()\ndata['MHC_sequence']=scaler.fit_transform(data[['MHC_sequence']])\ndata['peptide_sequence']=scaler.fit_transform(data[['peptide_sequence']])\ndata['MHC_type']=scaler.fit_transform(data[['MHC_type']])\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:27:51.004913Z","iopub.execute_input":"2023-12-14T22:27:51.005194Z","iopub.status.idle":"2023-12-14T22:27:51.080498Z","shell.execute_reply.started":"2023-12-14T22:27:51.005159Z","shell.execute_reply":"2023-12-14T22:27:51.079610Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1793065 entries, 0 to 1793064\nData columns (total 4 columns):\n #   Column            Dtype  \n---  ------            -----  \n 0   MHC_sequence      float64\n 1   MHC_type          float64\n 2   peptide_sequence  float64\n 3   label             int64  \ndtypes: float64(3), int64(1)\nmemory usage: 54.7 MB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Remove noise values**\n\nTo detect outliers in datasets, the z-score method can be utilized. This involves comparing data points with a threshold and subsequently eliminating any noisy values.","metadata":{}},{"cell_type":"code","source":"y = data['label']\n\ndata = data.drop(['label'],axis=1)\nz_scores = np.abs(stats.zscore(data))\n\n# Define a threshold for outlier detection\nthreshold = 3\n\n# Exclude rows with outliers in at least one column\ndata = data[(z_scores < threshold).all(axis=1)]\ny = y[(z_scores < threshold).all(axis=1)]","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:27:51.081701Z","iopub.execute_input":"2023-12-14T22:27:51.082044Z","iopub.status.idle":"2023-12-14T22:27:51.222080Z","shell.execute_reply.started":"2023-12-14T22:27:51.082012Z","shell.execute_reply":"2023-12-14T22:27:51.221282Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"print(mutual_info_score(data['MHC_sequence'], data['MHC_type']))","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:27:51.223168Z","iopub.execute_input":"2023-12-14T22:27:51.223484Z","iopub.status.idle":"2023-12-14T22:27:51.405777Z","shell.execute_reply.started":"2023-12-14T22:27:51.223459Z","shell.execute_reply":"2023-12-14T22:27:51.404879Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"3.990176283634478\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/cluster/_supervised.py:66: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and continuous values for target\n  warnings.warn(msg, UserWarning)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"At first, I thought that two features MHC_sequence and MHC_type are relevant, but after this examination, you can see that the mutual information rate isn't really high. so I cant merge this two features.","metadata":{}},{"cell_type":"markdown","source":"# **Train-Test Split**\nThe purpose of this split is to evaluate the model's performance on unseen data and assess its ability to generalize.","metadata":{}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test  = train_test_split(data, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:27:51.407202Z","iopub.execute_input":"2023-12-14T22:27:51.407526Z","iopub.status.idle":"2023-12-14T22:27:51.664826Z","shell.execute_reply.started":"2023-12-14T22:27:51.407499Z","shell.execute_reply":"2023-12-14T22:27:51.663983Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"x_train=x_train.to_numpy()\ny_train=y_train.to_numpy()\n\nx_test=x_test.to_numpy()\ny_test=y_test.to_numpy()\n\nx_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:27:51.666034Z","iopub.execute_input":"2023-12-14T22:27:51.666344Z","iopub.status.idle":"2023-12-14T22:27:51.693945Z","shell.execute_reply.started":"2023-12-14T22:27:51.666318Z","shell.execute_reply":"2023-12-14T22:27:51.692955Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"(1414369, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Building Feed Forward Neural Network**\nI also use **Regularization techniques** such as L1 and L2 regularization for preventing overfit in my feed-forward neural networks.","metadata":{}},{"cell_type":"code","source":"model = keras.models.Sequential()\n\nmodel.add(keras.layers.Dense(units=2,activation='relu',input_shape=(3,))) # Input Layer\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.Dense(units=16, activation='sigmoid'))\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.Dense(units=8, activation='relu',kernel_regularizer=keras.regularizers.l1(0.01)))\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.Dense(units=8, activation='sigmoid'))\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.Dense(units=4, activation='relu',kernel_regularizer=keras.regularizers.l2(0.01)))\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.Dense(units=4, activation='sigmoid'))\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.Dense(units=1, activation='softmax')) # Output Layer\n\nlearning_rate = 0.005\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:27:51.695625Z","iopub.execute_input":"2023-12-14T22:27:51.696318Z","iopub.status.idle":"2023-12-14T22:27:51.891913Z","shell.execute_reply.started":"2023-12-14T22:27:51.696275Z","shell.execute_reply":"2023-12-14T22:27:51.891111Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:27:51.893124Z","iopub.execute_input":"2023-12-14T22:27:51.893440Z","iopub.status.idle":"2023-12-14T22:27:51.933397Z","shell.execute_reply.started":"2023-12-14T22:27:51.893413Z","shell.execute_reply":"2023-12-14T22:27:51.932491Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_7 (Dense)             (None, 2)                 8         \n                                                                 \n batch_normalization_6 (Bat  (None, 2)                 8         \n chNormalization)                                                \n                                                                 \n dense_8 (Dense)             (None, 16)                48        \n                                                                 \n batch_normalization_7 (Bat  (None, 16)                64        \n chNormalization)                                                \n                                                                 \n dense_9 (Dense)             (None, 8)                 136       \n                                                                 \n batch_normalization_8 (Bat  (None, 8)                 32        \n chNormalization)                                                \n                                                                 \n dense_10 (Dense)            (None, 8)                 72        \n                                                                 \n batch_normalization_9 (Bat  (None, 8)                 32        \n chNormalization)                                                \n                                                                 \n dense_11 (Dense)            (None, 4)                 36        \n                                                                 \n batch_normalization_10 (Ba  (None, 4)                 16        \n tchNormalization)                                               \n                                                                 \n dense_12 (Dense)            (None, 4)                 20        \n                                                                 \n batch_normalization_11 (Ba  (None, 4)                 16        \n tchNormalization)                                               \n                                                                 \n dense_13 (Dense)            (None, 1)                 5         \n                                                                 \n=================================================================\nTotal params: 493 (1.93 KB)\nTrainable params: 409 (1.60 KB)\nNon-trainable params: 84 (336.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(\n    x_train,\n    y_train,\n    batch_size=1000,\n    epochs=5,\n    shuffle=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:27:51.934592Z","iopub.execute_input":"2023-12-14T22:27:51.934872Z","iopub.status.idle":"2023-12-14T22:28:52.448215Z","shell.execute_reply.started":"2023-12-14T22:27:51.934847Z","shell.execute_reply":"2023-12-14T22:28:52.447282Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Epoch 1/5\n1415/1415 [==============================] - 16s 8ms/step - loss: 0.5238 - accuracy: 0.2005\nEpoch 2/5\n1415/1415 [==============================] - 11s 8ms/step - loss: 0.5057 - accuracy: 0.2005\nEpoch 3/5\n1415/1415 [==============================] - 11s 8ms/step - loss: 0.5067 - accuracy: 0.2005\nEpoch 4/5\n1415/1415 [==============================] - 11s 8ms/step - loss: 0.5053 - accuracy: 0.2005\nEpoch 5/5\n1415/1415 [==============================] - 11s 8ms/step - loss: 0.5123 - accuracy: 0.2005\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7d1160528790>"},"metadata":{}}]},{"cell_type":"code","source":"model.evaluate(x_test, y_test, batch_size=100)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T22:28:52.449808Z","iopub.execute_input":"2023-12-14T22:28:52.450170Z","iopub.status.idle":"2023-12-14T22:29:02.296688Z","shell.execute_reply.started":"2023-12-14T22:28:52.450136Z","shell.execute_reply":"2023-12-14T22:29:02.295727Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"3536/3536 [==============================] - 10s 3ms/step - loss: 0.5307 - accuracy: 0.1998\n","output_type":"stream"},{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"[0.5307197570800781, 0.199757918715477]"},"metadata":{}}]},{"cell_type":"markdown","source":"My model has a underfitting problem. I can change features structure for example using only character-level encoding without using pca but it doesn't work for me because I have finite resources. So I should provide a deeper understanding and more accurate interpretation of the data for feature selection and encoding data to fix this problem and aslo balance the trade-off between memory and time.","metadata":{}}]}